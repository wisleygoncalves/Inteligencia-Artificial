
# ğŸ¤– Curso de Machine Learning AvanÃ§ado

Este repositÃ³rio contÃ©m **anotaÃ§Ãµes, cÃ³digos e explicaÃ§Ãµes prÃ¡ticas** dos principais tÃ³picos avanÃ§ados de Machine Learning, com foco em otimizaÃ§Ã£o de atributos, reduÃ§Ã£o de dimensionalidade, algoritmos nÃ£o supervisionados avanÃ§ados, tÃ©cnicas para lidar com bases desbalanceadas e uso de AutoML.

---

## ğŸ“˜ Ãndice

1. [âš™ï¸ Engenharia e SeleÃ§Ã£o de Atributos](#ï¸-engenharia-e-seleÃ§Ã£o-de-atributos)  
2. [ğŸ“‰ PCA - Principal Component Analysis](#-pca---principal-component-analysis)  
3. [ğŸ”¬ TÃ©cnicas AvanÃ§adas para Clusters](#-tÃ©cnicas-avanÃ§adas-para-clusters)  
4. [ğŸ·ï¸ ClassificaÃ§Ã£o Multi Label](#ï¸-classificaÃ§Ã£o-multi-label)  
5. [âš–ï¸ Dados Desbalanceados](#ï¸-dados-desbalanceados)  
6. [ğŸ¤– AutoML e Tunning de Modelos](#-automl-e-tunning-de-modelos)  

---

## âš™ï¸ Engenharia e SeleÃ§Ã£o de Atributos

### IntroduÃ§Ã£o
- Processo de preparar os dados para aumentar a performance dos modelos.  
- TÃ©cnicas incluem: transformaÃ§Ã£o de variÃ¡veis, criaÃ§Ã£o de atributos derivados, normalizaÃ§Ã£o e padronizaÃ§Ã£o.

### SeleÃ§Ã£o de Atributos
- MÃ©todos estatÃ­sticos (ANOVA, Qui-quadrado, CorrelaÃ§Ã£o de Pearson).
- MÃ©todos baseados em modelos (Random Forest, Lasso).
- EliminaÃ§Ã£o recursiva de atributos (*Recursive Feature Elimination*).

### Labs:
- ğŸ“ `atribute_engineering.py`  
- ğŸ“ `feature_selection.ipynb`  

---

## ğŸ“‰ PCA - Principal Component Analysis

### IntroduÃ§Ã£o
- TÃ©cnica de reduÃ§Ã£o de dimensionalidade.
- Converte variÃ¡veis correlacionadas em componentes ortogonais.

### Conceitos
- MaximizaÃ§Ã£o da variÃ¢ncia explicada.
- Autovalores e autovetores da matriz de covariÃ¢ncia.

### Vantagens
- Reduz ruÃ­do.
- Aumenta desempenho de modelos.
- VisualizaÃ§Ã£o em espaÃ§o reduzido.

### Labs:
- ğŸ“ `pca_analysis.ipynb`  
- ğŸ“ `lab_pca.py`

---

## ğŸ”¬ TÃ©cnicas AvanÃ§adas para Clusters

### IntroduÃ§Ã£o
- AlÃ©m do KMeans, outras tÃ©cnicas de agrupamento podem lidar com dados complexos.

### Algoritmos
- **DBSCAN**: detecta clusters de forma arbitrÃ¡ria e identifica ruÃ­do.  
- **Clustering Aglomerativo**: hierÃ¡rquico, gera dendrogramas.  
- **Escolha do NÃºmero Ã“timo de Clusters**: mÃ©todos como Elbow, Silhouette, Hopkins e VAT.  

### Labs:
- ğŸ“ `advanced_clustering.py`  
- ğŸ“ `lab_clusters.ipynb`  

---

## ğŸ·ï¸ ClassificaÃ§Ã£o Multi Label

### IntroduÃ§Ã£o
- Problemas em que uma instÃ¢ncia pode pertencer a **mÃºltiplas classes ao mesmo tempo**.  
- Exemplo: um filme pode ser classificado como *AÃ§Ã£o* e *ComÃ©dia*.

### AvaliaÃ§Ã£o
- **Hamming Loss**  
- **Micro/Macro F1-Score**  
- **Subset Accuracy**

### Labs:
- ğŸ“ `multi_label_classification.py`  
- ğŸ“ `lab_multi_label.ipynb`  

---

## âš–ï¸ Dados Desbalanceados

### IntroduÃ§Ã£o
- Problema comum em datasets reais (ex: fraudes, doenÃ§as raras).  
- Classes majoritÃ¡rias dominam a prediÃ§Ã£o.

### TÃ©cnicas
- **Oversampling** (SMOTE).  
- **Undersampling**.  
- **Class Weights**.  

### Labs:
- ğŸ“ `imbalanced_data.py`  
- ğŸ“ `lab_imbalanced.ipynb`  

---

## ğŸ¤– AutoML e Tunning de Modelos

### IntroduÃ§Ã£o
- **AutoML**: automaÃ§Ã£o do processo de seleÃ§Ã£o de modelos e hiperparÃ¢metros.  
- **Tunning**: ajuste fino com *Grid Search*, *Random Search* e *Bayesian Optimization*.  

### Ferramentas
- `sklearn.model_selection` (GridSearchCV, RandomizedSearchCV).  
- **H2O AutoML** para pipelines completos.  

### Labs:
- ğŸ“ `automl_tunning.py`  
- ğŸ“ `lab_automl.ipynb`  
- ğŸ“ `lab_h2o_automl.ipynb`  

---

## ğŸ“‚ Requisitos

```bash
pip install numpy pandas matplotlib seaborn scikit-learn statsmodels mlxtend imbalanced-learn h2o
```

